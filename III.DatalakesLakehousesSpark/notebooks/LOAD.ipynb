{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21f3b72a-011c-479b-afe4-8f73c20ad831",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# LOAD data from Delta files to create staging tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06d72340-8202-4b8b-bce2-c9622298deaa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 1. Payment staging table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d076ddd1-b871-4f21-916e-c04a7bcd3399",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop if exist\n",
    "if (spark._jsparkSession.catalog().tableExists('default', 'stagingPayment') == True):\n",
    "    spark.sql(\"DROP TABLE IF EXISTS stagingPayment\")\n",
    "\n",
    "# Create staging table for Payment data\n",
    "spark.sql(\"CREATE TABLE stagingPayment USING DELTA LOCATION '/delta/payments'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06a9e2b5-d2cf-42e5-b8a8-a502257c7b9c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 2. Trip staging table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "416cac51-cedc-48ff-9a12-690ac6c808e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop if exist\n",
    "if (spark._jsparkSession.catalog().tableExists('default', 'stagingTrip') == True):\n",
    "    spark.sql(\"DROP TABLE IF EXISTS stagingTrip\")\n",
    "\n",
    "# Create staging table for Trip data\n",
    "spark.sql(\"CREATE TABLE stagingTrip USING DELTA LOCATION '/delta/trips'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "12d9d378-440b-4c5b-9730-51e58088ce8a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 3. Rider staging table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "200c81b9-1560-45a0-893e-392435b9c1c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop if exist\n",
    "if (spark._jsparkSession.catalog().tableExists('default', 'stagingRider') == True):\n",
    "    spark.sql(\"DROP TABLE IF EXISTS stagingRider\")\n",
    "\n",
    "# Create staging table for Rider data\n",
    "spark.sql(\"CREATE TABLE stagingRider USING DELTA LOCATION '/delta/riders'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "17a786e7-361a-4ac3-ae2a-5227651dadca",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 4. Station staging table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5825511a-f627-40e9-97f6-af097e31a1dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop if exist\n",
    "if (spark._jsparkSession.catalog().tableExists('default', 'stagingStation') == True):\n",
    "    spark.sql(\"DROP TABLE IF EXISTS stagingStation\")\n",
    "\n",
    "# Create staging table for Station data\n",
    "spark.sql(\"CREATE TABLE stagingStation USING DELTA LOCATION '/delta/stations'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b334633-642b-4860-a4d8-b8caab44af89",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## 5. Date staging table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b930f8c2-8dd4-441b-9390-20c6a8480081",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop if exist\n",
    "if (spark._jsparkSession.catalog().tableExists('default', 'stagingDate') == True):\n",
    "    spark.sql(\"DROP TABLE IF EXISTS stagingDate\")\n",
    "\n",
    "# Create staging table for Date data\n",
    "spark.sql(\"CREATE TABLE stagingDate USING DELTA LOCATION '/delta/dates'\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LOAD",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
